{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d6a04263-186d-4c70-a291-f196c9a8da67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward as ak\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import pathlib\n",
    "from typing import List, Optional\n",
    "\n",
    "from coffea import processor\n",
    "from coffea.nanoevents.methods import candidate, vector\n",
    "from coffea.analysis_tools import Weights, PackedSelection\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Found duplicate branch \")\n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6682d0d5-f3b0-40ac-b87b-d1dfb5546c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from coffea casa\n",
    "# import uproot\n",
    "# f = uproot.open('root://xcache//store/mc/RunIISummer19UL17NanoAODv2/GluGluHToWWToLNuQQ_M125_TuneCP5_PSweight_13TeV-powheg2-jhugen727-pythia8/NANOAODSIM/106X_mc2017_realistic_v8-v1/250000/13D6BBD5-89E3-8647-AED6-FB5DFAAF4C8C.root:Events')\n",
    "# f.num_entries   ### checks number of events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d10df933-1d90-472f-8334-29f2b032b2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_val(\n",
    "    arr: ak.Array,\n",
    "    value: float,\n",
    "    target: int = None,\n",
    "    axis: int = 0,\n",
    "    to_numpy: bool = False,\n",
    "    clip: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    pads awkward array up to ``target`` index along axis ``axis`` with value ``value``,\n",
    "    optionally converts to numpy array\n",
    "    \"\"\"\n",
    "    if target:\n",
    "        ret = ak.fill_none(ak.pad_none(arr, target, axis=axis, clip=clip), value, axis=None)\n",
    "    else:\n",
    "        ret = ak.fill_none(arr, value, axis=None)\n",
    "    return ret.to_numpy() if to_numpy else ret\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "def dsum(*dicts):\n",
    "    ret = defaultdict(int)\n",
    "    for d in dicts:\n",
    "        for k, v in d.items():\n",
    "            ret[k] += v\n",
    "    return dict(ret)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30e5afd3-d755-4a56-a832-9ff376e31fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getParticles(genparticles,lowid=22,highid=25,flags=['fromHardProcess', 'isLastCopy']):\n",
    "    \"\"\"\n",
    "    returns the particle objects that satisfy a low id, \n",
    "    high id condition and have certain flags\n",
    "    \"\"\"\n",
    "    absid = abs(genparticles.pdgId)\n",
    "    return genparticles[\n",
    "        ((absid >= lowid) & (absid <= highid))\n",
    "        & genparticles.hasFlags(flags)\n",
    "    ]\n",
    "\n",
    "def match_HWWlepqq(genparticles,candidatefj):\n",
    "    \"\"\"\n",
    "    return the number of matched objects (hWW*),daughters, \n",
    "    and gen flavor (enuqq, munuqq, taunuqq) \n",
    "    \"\"\"\n",
    "    W_PDGID = 24\n",
    "    HIGGS_PDGID = 25\n",
    "    higgs = getParticles(genparticles,HIGGS_PDGID)\n",
    "    is_hWW = ak.all(abs(higgs.children.pdgId)==W_PDGID,axis=2)\n",
    "\n",
    "    higgs = higgs[is_hWW]\n",
    "    higgs_wstar = higgs.children[ak.argmin(higgs.children.mass,axis=2,keepdims=True)]\n",
    "    higgs_w = higgs.children[ak.argmax(higgs.children.mass,axis=2,keepdims=True)]\n",
    "    \n",
    "    prompt_electron = getParticles(genparticles,11,11,['isPrompt','isLastCopy'])\n",
    "    prompt_muon = getParticles(genparticles,13,13,['isPrompt', 'isLastCopy'])\n",
    "    prompt_tau = getParticles(genparticles,15,15,['isPrompt', 'isLastCopy'])\n",
    "    prompt_q = getParticles(genparticles,0,5,['fromHardProcess', 'isLastCopy'])\n",
    "    prompt_q = prompt_q[abs(prompt_q.distinctParent.pdgId) == W_PDGID]\n",
    "    \n",
    "    dr_fj_quarks = candidatefj.delta_r(prompt_q)\n",
    "    dr_fj_electrons = candidatefj.delta_r(prompt_electron)\n",
    "    dr_fj_muons = candidatefj.delta_r(prompt_muon)\n",
    "    dr_fj_taus = candidatefj.delta_r(prompt_tau)\n",
    "    dr_daughters = ak.concatenate([dr_fj_quarks,dr_fj_electrons,dr_fj_muons,dr_fj_taus],axis=1)\n",
    "    hWWlepqq_nprongs = ak.sum(dr_daughters<0.8,axis=1)\n",
    "    \n",
    "    n_electrons = ak.sum(prompt_electron.pt>0,axis=1)\n",
    "    n_muons = ak.sum(prompt_muon.pt>0,axis=1)\n",
    "    n_taus = ak.sum(prompt_tau.pt>0,axis=1)\n",
    "    n_quarks = ak.sum(prompt_q.pt>0,axis=1)\n",
    "\n",
    "    # 4(elenuqq),6(munuqq),8(taunuqq)\n",
    "    hWWlepqq_flavor = (n_quarks==2)*1 + (n_electrons==1)*3 + (n_muons==1)*5 + (n_taus==1)*7\n",
    "    \n",
    "    matchedH = candidatefj.nearest(higgs, axis=1, threshold=0.8)\n",
    "    matchedW = candidatefj.nearest(higgs_w, axis=1, threshold=0.8)\n",
    "    matchedWstar = candidatefj.nearest(higgs_wstar, axis=1, threshold=0.8) \n",
    "\n",
    "    # 1 (H only), 4(W), 6(W star), 9(H, W and Wstar)\n",
    "    hWWlepqq_matched = (\n",
    "        (ak.sum(matchedH.pt > 0, axis=1)==1) * 1 \n",
    "        + (ak.sum(ak.flatten(matchedW.pt > 0, axis=2), axis=1)==1) * 3 \n",
    "        + (ak.sum(ak.flatten(matchedWstar.pt > 0, axis=2), axis=1)==1) * 5\n",
    "    )\n",
    "    \n",
    "    # leptons matched\n",
    "    dr_leptons = ak.concatenate([dr_fj_electrons,dr_fj_muons], axis=1)\n",
    "    matched_leptons = dr_leptons < 0.8\n",
    "    \n",
    "    leptons = ak.concatenate([prompt_electron, prompt_muon], axis=1)\n",
    "    leptons = leptons[matched_leptons]\n",
    "    \n",
    "    # leptons coming from W or W*\n",
    "    leptons_mass = ak.firsts(leptons.distinctParent.mass)\n",
    "    higgs_w_mass = ak.firsts(ak.flatten(higgs_w.mass))[ak.firsts(leptons.pt > 0)]\n",
    "    higgs_wstar_mass = ak.firsts(ak.flatten(higgs_wstar.mass))[ak.firsts(leptons.pt > 0)]\n",
    "\n",
    "    iswlepton = (leptons_mass == higgs_w_mass)\n",
    "    iswstarlepton = (leptons_mass == higgs_wstar_mass)\n",
    "    \n",
    "    # let's return only:\n",
    "    # - matchedH (the higgs boson that is matched to the jet)\n",
    "    # - (iswlepton,iswstarlepton)\n",
    "    return matchedH, iswlepton, iswstarlepton, higgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e338aa9-c4ff-4765-b66d-585ad1d90e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HwwProcessor(processor.ProcessorABC):\n",
    "    def __init__(self, year=\"2017\", yearmod=\"\", channels=[\"ele\", \"mu\", \"had\"], output_location=\"./\", folder_name=''):\n",
    "        self._year = year\n",
    "        self._yearmod = yearmod\n",
    "        self._channels = channels\n",
    "        self._output_location = output_location\n",
    "        self.folder_name = folder_name\n",
    "\n",
    "        # define variables to save for each channel\n",
    "        self._skimvars = {\n",
    "            'ele': [\n",
    "                \"lepton_pt\",\n",
    "                \"lep_isolation\",\n",
    "                \"met\",\n",
    "                \"ht\",\n",
    "                \"mt_lep_met\",\n",
    "                \"dr_jet_candlep\",\n",
    "            ],\n",
    "            'mu': [\n",
    "                \"lepton_pt\",\n",
    "                \"lep_isolation\",\n",
    "                \"met\",\n",
    "                \"ht\",\n",
    "                \"mt_lep_met\",\n",
    "                \"dr_jet_candlep\",\n",
    "                \"mu_mvaId\"\n",
    "            ],\n",
    "            'had': [\n",
    "                \"leadingfj_pt\",\n",
    "                \"leadingfj_msoftdrop\",\n",
    "                \"secondfj_pt\",\n",
    "                \"secondfj_msoftdrop\",\n",
    "                \"met\",\n",
    "                \"ht\",\n",
    "                \"bjets_ophem_leadingfj\"\n",
    "            ],\n",
    "        }\n",
    "\n",
    "        # trigger paths\n",
    "        self._HLTs = {\n",
    "            2016: {\n",
    "                'ele': [\n",
    "                    \"Ele27_WPTight_Gsf\",\n",
    "                    \"Ele115_CaloIdVT_GsfTrkIdT\",\n",
    "                    \"Photon175\",\n",
    "                    # \"Ele50_CaloIdVT_GsfTrkIdT_PFJet165\", # extra\n",
    "                    # \"Ele15_IsoVVVL_PFHT600\", # VVL\n",
    "                ],\n",
    "                'mu': [\n",
    "                    \"Mu50\",\n",
    "                    \"TkMu50\",\n",
    "                    \"IsoMu24\",\n",
    "                    \"IsoTkMu24\",\n",
    "                    # \"Mu55\",\n",
    "                    # \"Mu15_IsoVVVL_PFHT600\" # VVL\n",
    "                ],\n",
    "                'had': [\n",
    "                    \"PFHT800\",\n",
    "                    \"PFHT900\",\n",
    "                    \"AK8PFJet360_TrimMass30\",\n",
    "                    \"AK8PFHT700_TrimR0p1PT0p03Mass50\",\n",
    "                    \"PFHT650_WideJetMJJ950DEtaJJ1p5\",\n",
    "                    \"PFHT650_WideJetMJJ900DEtaJJ1p5\",\n",
    "                    \"PFJet450\",\n",
    "                ],\n",
    "            },\n",
    "            2017: {\n",
    "                'ele': [\n",
    "                    \"Ele35_WPTight_Gsf\",\n",
    "                    \"Ele115_CaloIdVT_GsfTrkIdT\",\n",
    "                    \"Photon200\",\n",
    "                    # \"Ele50_CaloIdVT_GsfTrkIdT_PFJet165\", # extra\n",
    "                    # \"Ele15_IsoVVVL_PFHT600\", # VVL\n",
    "                ],\n",
    "                'mu': [\n",
    "                    \"Mu50\",\n",
    "                    \"IsoMu27\",\n",
    "                    \"OldMu100\",\n",
    "                    \"TkMu100\",\n",
    "                    # \"Mu15_IsoVVVL_PFHT600\", # VVL\n",
    "                ],\n",
    "                'had': [\n",
    "                    \"PFHT1050\",\n",
    "                    \"AK8PFJet400_TrimMass30\",\n",
    "                    \"AK8PFJet420_TrimMass30\",\n",
    "                    \"AK8PFHT800_TrimMass50\",\n",
    "                    \"PFJet500\",\n",
    "                    \"AK8PFJet500\",\n",
    "                ],\n",
    "            },\n",
    "            2018: {\n",
    "                'ele': [\n",
    "                    \"Ele32_WPTight_Gsf\",\n",
    "                    \"Ele115_CaloIdVT_GsfTrkIdT\",\n",
    "                    \"Photon200\",\n",
    "                    # \"Ele50_CaloIdVT_GsfTrkIdT_PFJet165\", # extra\n",
    "                    # \"Ele15_IsoVVVL_PFHT600\", # VVL\n",
    "                ],\n",
    "                'mu': [\n",
    "                    \"Mu50\",\n",
    "                    \"IsoMu24\",\n",
    "                    \"OldMu100\",\n",
    "                    \"TkMu100\",\n",
    "                    # \"Mu15_IsoVVVL_PFHT600\", # VVL\n",
    "                ],\n",
    "                'had': [\n",
    "                    \"PFHT1050\",\n",
    "                    \"AK8PFJet400_TrimMass30\",\n",
    "                    \"AK8PFJet420_TrimMass30\",\n",
    "                    \"AK8PFHT800_TrimMass50\",\n",
    "                    \"PFJet500\",\n",
    "                    \"AK8PFJet500\",\n",
    "                ],\n",
    "            }\n",
    "        }[int(self._year)]\n",
    "\n",
    "        # https://twiki.cern.ch/twiki/bin/view/CMS/MissingETOptionalFiltersRun2\n",
    "        self._metfilters = {\n",
    "            2016: [\n",
    "                \"goodVertices\",\n",
    "                \"globalSuperTightHalo2016Filter\",\n",
    "                \"HBHENoiseFilter\",\n",
    "                \"HBHENoiseIsoFilter\",\n",
    "                \"EcalDeadCellTriggerPrimitiveFilter\",\n",
    "                \"BadPFMuonFilter\",\n",
    "                \"eeBadScFilter\",\n",
    "            ],\n",
    "            2017: [\n",
    "                \"goodVertices\",\n",
    "                \"globalSuperTightHalo2016Filter\",\n",
    "                \"HBHENoiseFilter\",\n",
    "                \"HBHENoiseIsoFilter\",\n",
    "                \"EcalDeadCellTriggerPrimitiveFilter\",\n",
    "                \"BadPFMuonFilter\",\n",
    "                # \"BadChargedCandidateFilter\",\n",
    "                \"eeBadScFilter\",\n",
    "                \"ecalBadCalibFilter\",\n",
    "            ],\n",
    "            2018:  [\n",
    "                \"goodVertices\",\n",
    "                \"globalSuperTightHalo2016Filter\",\n",
    "                \"HBHENoiseFilter\",\n",
    "                \"HBHENoiseIsoFilter\",\n",
    "                \"EcalDeadCellTriggerPrimitiveFilter\",\n",
    "                \"BadPFMuonFilter\",\n",
    "                # \"BadChargedCandidateFilter\",\n",
    "                \"eeBadScFilter\",\n",
    "                \"ecalBadCalibFilter\",\n",
    "            ],\n",
    "        }[int(self._year)]\n",
    "\n",
    "        # https://twiki.cern.ch/twiki/bin/viewauth/CMS/BtagRecommendation\n",
    "        self._btagWPs = {\n",
    "            '2016preVFP': {\n",
    "                'loose': 0.0508,\n",
    "                'medium': 0.2598,\n",
    "                'tight': 0.6502,\n",
    "            },\n",
    "            '2016postVFP': {\n",
    "                'loose': 0.0480,\n",
    "                'medium': 0.2489,\n",
    "                'tight': 0.6377,\n",
    "            },\n",
    "            '2017': {\n",
    "                'loose': 0.0532,\n",
    "                'medium': 0.3040,\n",
    "                'tight': 0.7476,\n",
    "            },\n",
    "            '2018': {\n",
    "                'loose': 0.0490,\n",
    "                'medium': 0.2783,\n",
    "                'tight': 0.7100,\n",
    "            },\n",
    "        }[year + yearmod]\n",
    "\n",
    "        self.selections = {}\n",
    "        self.cutflows = {}\n",
    "\n",
    "    @property\n",
    "    def accumulator(self):\n",
    "        return self._accumulator\n",
    "\n",
    "    def save_dfs_parquet(self, fname, dfs_dict, ch, folder_name):\n",
    "        if self._output_location is not None:\n",
    "            table = pa.Table.from_pandas(dfs_dict)\n",
    "            pq.write_table(table, './outfiles/' + ch + folder_name + '/parquet/' + fname + '.parquet')\n",
    "\n",
    "    def ak_to_pandas(self, output_collection: ak.Array) -> pd.DataFrame:\n",
    "        output = pd.DataFrame()\n",
    "        for field in ak.fields(output_collection):\n",
    "            output[field] = ak.to_numpy(output_collection[field])\n",
    "        return output\n",
    "\n",
    "    def add_selection(self, name: str, sel: np.ndarray, channel: list = None):\n",
    "        \"\"\"Adds selection to PackedSelection object and the cutflow dictionary\"\"\"\n",
    "        channels = channel if channel else self._channels\n",
    "        for ch in channels:\n",
    "            self.selections[ch].add(name, sel)\n",
    "            self.cutflows[ch][name] = np.sum(self.selections[ch].all(*self.selections[ch].names))\n",
    "\n",
    "    def process(self, events: ak.Array):\n",
    "        \"\"\"Returns skimmed events which pass preselection cuts and with the branches listed in self._skimvars\"\"\"\n",
    "        dataset = events.metadata['dataset']\n",
    "        isMC = hasattr(events, \"genWeight\")\n",
    "        sumgenweight = ak.sum(events.genWeight) if isMC else 0\n",
    "        nevents = len(events)\n",
    "\n",
    "        # empty selections and cutflows\n",
    "        self.selections = {}\n",
    "        self.cutflows = {}\n",
    "        for ch in self._channels:\n",
    "            self.selections[ch] = PackedSelection()\n",
    "            self.cutflows[ch] = {}\n",
    "            self.cutflows[ch][\"all\"] = nevents\n",
    "\n",
    "        # trigger\n",
    "        triggers = {}\n",
    "        for ch in self._channels:\n",
    "            if ch == \"had\" and isMC:\n",
    "                trigger = np.ones(nevents, dtype='bool')\n",
    "            else:\n",
    "                # apply trigger to both data and MC (except for hadronic channel)\n",
    "                trigger = np.zeros(len(events), dtype='bool')\n",
    "                for t in self._HLTs[ch]:\n",
    "                    if t in events.HLT.fields:\n",
    "                        trigger = trigger | events.HLT[t]\n",
    "            self.add_selection(\"trigger\", trigger, [ch])\n",
    "            del trigger\n",
    "\n",
    "        # metfilters\n",
    "        metfilters = np.ones(nevents, dtype='bool')\n",
    "        for mf in self._metfilters:\n",
    "            if mf in events.Flag.fields:\n",
    "                metfilters = metfilters & events.Flag[mf]\n",
    "        self.add_selection(\"metfilters\", metfilters)\n",
    "\n",
    "        # define muon objects\n",
    "        loose_muons = (\n",
    "            (((events.Muon.pt > 30) & (events.Muon.pfRelIso04_all < 0.25)) |\n",
    "             (events.Muon.pt > 55))\n",
    "            & (np.abs(events.Muon.eta) < 2.4)\n",
    "            & (events.Muon.looseId)\n",
    "        )\n",
    "        n_loose_muons = ak.sum(loose_muons, axis=1)\n",
    "\n",
    "        good_muons = (\n",
    "            (events.Muon.pt > 28)\n",
    "            & (np.abs(events.Muon.eta) < 2.4)\n",
    "            & (np.abs(events.Muon.dz) < 0.1)\n",
    "            & (np.abs(events.Muon.dxy) < 0.05)\n",
    "            & (events.Muon.sip3d <= 4.0)\n",
    "            & events.Muon.mediumId\n",
    "        )\n",
    "        n_good_muons = ak.sum(good_muons, axis=1)\n",
    "\n",
    "        # define electron objects\n",
    "        loose_electrons = (\n",
    "            (((events.Electron.pt > 38) & (events.Electron.pfRelIso03_all < 0.25)) |\n",
    "             (events.Electron.pt > 120))\n",
    "            & ((np.abs(events.Electron.eta) < 1.44) | (np.abs(events.Electron.eta) > 1.57))\n",
    "            & (events.Electron.cutBased >= events.Electron.LOOSE)\n",
    "        )\n",
    "        n_loose_electrons = ak.sum(loose_electrons, axis=1)\n",
    "\n",
    "        good_electrons = (\n",
    "            (events.Electron.pt > 38)\n",
    "            & ((np.abs(events.Electron.eta) < 1.44) | (np.abs(events.Electron.eta) > 1.57))\n",
    "            & (np.abs(events.Electron.dz) < 0.1)\n",
    "            & (np.abs(events.Electron.dxy) < 0.05)\n",
    "            & (events.Electron.sip3d <= 4.0)\n",
    "            & (events.Electron.mvaFall17V2noIso_WP90)\n",
    "        )\n",
    "        n_good_electrons = ak.sum(good_electrons, axis=1)\n",
    "\n",
    "        # leading lepton\n",
    "        goodleptons = ak.concatenate([events.Muon[good_muons], events.Electron[good_electrons]], axis=1)\n",
    "        goodleptons = goodleptons[ak.argsort(goodleptons.pt, ascending=False)]\n",
    "        candidatelep = ak.firsts(goodleptons)\n",
    "\n",
    "        # candidate leptons\n",
    "        candidatelep_p4 = ak.zip(\n",
    "            {\n",
    "                \"pt\": candidatelep.pt,\n",
    "                \"eta\": candidatelep.eta,\n",
    "                \"phi\": candidatelep.phi,\n",
    "                \"mass\": candidatelep.mass,\n",
    "                \"charge\": candidatelep.charge,\n",
    "            },\n",
    "            with_name=\"PtEtaPhiMCandidate\",\n",
    "            behavior=candidate.behavior,\n",
    "        )\n",
    "\n",
    "        # relative isolation\n",
    "        lep_reliso = candidatelep.pfRelIso04_all if hasattr(candidatelep, \"pfRelIso04_all\") else candidatelep.pfRelIso03_all\n",
    "        # mini isolation\n",
    "        mu_miso = candidatelep.miniPFRelIso_all\n",
    "        # MVA-ID\n",
    "        mu_mvaId = candidatelep.mvaId if hasattr(candidatelep, \"mvaId\") else np.zeros(nevents)\n",
    "\n",
    "        # JETS\n",
    "        goodjets = events.Jet[\n",
    "            (events.Jet.pt > 30)\n",
    "            & (abs(events.Jet.eta) < 2.5)\n",
    "            & events.Jet.isTight\n",
    "        ]\n",
    "        ht = ak.sum(goodjets.pt, axis=1)\n",
    "\n",
    "        # FATJETS\n",
    "        fatjets = events.FatJet\n",
    "        fatjets[\"qcdrho\"] = 2 * np.log(fatjets.msoftdrop / fatjets.pt)\n",
    "\n",
    "        good_fatjets = (\n",
    "            (fatjets.pt > 200)\n",
    "            & (abs(fatjets.eta) < 2.5)\n",
    "            & fatjets.isTight\n",
    "            # & fatjets.puId==7   #### TODO field not found\n",
    "        )\n",
    "        n_fatjets = ak.sum(good_fatjets, axis=1)\n",
    "\n",
    "        good_fatjets = fatjets[good_fatjets]\n",
    "        good_fatjets = good_fatjets[ak.argsort(good_fatjets.pt, ascending=False)]\n",
    "        leadingfj = ak.firsts(good_fatjets)\n",
    "        secondfj = ak.pad_none(good_fatjets, 2, axis=1)[:, 1]\n",
    "\n",
    "        candidatefj_lep = ak.firsts(good_fatjets[ak.argmin(good_fatjets.delta_r(candidatelep_p4), axis=1, keepdims=True)])\n",
    "        # lepton and fatjet mass\n",
    "        lep_fj_m = (candidatefj_lep - candidatelep_p4).mass\n",
    "\n",
    "        dphi_jet_lepfj = abs(goodjets.delta_phi(candidatefj_lep))  # ele and mu\n",
    "        dphi_jet_leadingfj = abs(goodjets.delta_phi(leadingfj))  # had\n",
    "\n",
    "        bjets_ophem_lepfj = ak.max(goodjets[dphi_jet_lepfj > np.pi / 2].btagDeepFlavB, axis=1)  # in event, pick highest b score in opposite direction from signal\n",
    "        bjets_ophem_leadingfj = ak.max(goodjets[dphi_jet_leadingfj > np.pi / 2].btagDeepFlavB, axis=1)\n",
    "\n",
    "        # deltaR\n",
    "        dr_jet_candlep = candidatefj_lep.delta_r(candidatelep_p4)\n",
    "\n",
    "        # MET\n",
    "        met = events.MET\n",
    "        mt_lep_met = np.sqrt(\n",
    "            2. * candidatelep_p4.pt * met.pt * (ak.ones_like(met.pt) - np.cos(candidatelep_p4.delta_phi(met)))\n",
    "        )\n",
    "\n",
    "        # event selections\n",
    "        self.add_selection(\n",
    "            name='leptonKin',\n",
    "            sel=(candidatelep.pt > 30),\n",
    "            channel=['mu']\n",
    "        )\n",
    "        self.add_selection(\n",
    "            name='oneLepton',\n",
    "            sel=(n_good_muons == 1) & (n_good_electrons == 0) & (n_loose_electrons == 0),\n",
    "            channel=['mu']\n",
    "        )\n",
    "        self.add_selection('leptonIsolation', sel=(\n",
    "            ((candidatelep.pt > 30)\n",
    "             & (candidatelep.pt < 55)\n",
    "             & (lep_reliso < 0.25)\n",
    "             )\n",
    "            | ((candidatelep.pt >= 55)\n",
    "               & (candidatelep.miniPFRelIso_all < 0.2))\n",
    "        ), channel=['mu'])\n",
    "        self.add_selection('leptonInJet', sel=(dr_jet_candlep < 0.8), channel=['mu', 'ele'])\n",
    "        self.add_selection('ht', sel=(ht > 200), channel=['mu', 'ele'])\n",
    "        self.add_selection('mt', sel=(mt_lep_met < 100), channel=['mu', 'ele'])\n",
    "        # self.add_selection(\n",
    "        #     name='bjet_tag',\n",
    "        #     sel=(bjets_ophem_lepfj > self._btagWPs[\"medium\"]),\n",
    "        #     channel=['mu', 'ele']\n",
    "        # )\n",
    "        # selections for electrons\n",
    "        self.add_selection(\n",
    "            name='leptonKin',\n",
    "            sel=(candidatelep.pt > 40),\n",
    "            channel=['ele']\n",
    "        )\n",
    "        self.add_selection(\n",
    "            name='oneLepton',\n",
    "            sel=(n_good_muons == 0) & (n_loose_muons == 0) & (n_good_electrons == 1),\n",
    "            channel=['ele']\n",
    "        )\n",
    "        self.add_selection('leptonIsolation', sel=(\n",
    "            ((candidatelep.pt > 30)\n",
    "             & (candidatelep.pt < 120)\n",
    "             & (lep_reliso < 0.3)\n",
    "             )\n",
    "            | ((candidatelep.pt >= 120)\n",
    "               & (candidatelep.miniPFRelIso_all < 0.2))\n",
    "        ), channel=['ele'])\n",
    "\n",
    "        # had selection\n",
    "        self.add_selection(\n",
    "            name='oneFatjet',\n",
    "            sel=(n_fatjets >= 1) & (n_good_muons == 0) & (n_loose_muons == 0) & (n_good_electrons == 0) & (n_loose_electrons == 0),\n",
    "            channel=['had']\n",
    "        )\n",
    "        self.add_selection(\n",
    "            name='leadingJet',\n",
    "            sel=leadingfj.pt > 450,\n",
    "            channel=['had']\n",
    "        )\n",
    "        self.add_selection(\n",
    "            name='softdrop',\n",
    "            sel=leadingfj.msoftdrop > 30,\n",
    "            channel=['had']\n",
    "        )\n",
    "        self.add_selection(\n",
    "            name='qcdrho',\n",
    "            sel=(leadingfj.qcdrho > -7) & (leadingfj.qcdrho < -2.0),\n",
    "            channel=['had']\n",
    "        )\n",
    "#         self.add_selection(\n",
    "#             name='bjet_tag',\n",
    "#             sel=(bjets_ophem_leadingfj > self._btagWPs[\"medium\"]),\n",
    "#             channel=['had']\n",
    "#         )\n",
    "\n",
    "        # initialize pandas dataframe\n",
    "        output = {}\n",
    "        for ch in self._channels:\n",
    "            out = {}\n",
    "            for var in self._skimvars[ch]:\n",
    "                if var == \"lepton_pt\":\n",
    "                    value = pad_val(candidatelep.pt, -1)\n",
    "                    out[var] = value\n",
    "                if var == \"dr_jet_candlep\":\n",
    "                    value = pad_val(dr_jet_candlep, -1)\n",
    "                    out[var] = value\n",
    "                if var == \"mt_lep_met\":\n",
    "                    value = pad_val(mt_lep_met, -1)\n",
    "                    out[var] = value\n",
    "                if var == \"ht\":\n",
    "                    value = pad_val(ht, -1)\n",
    "                    out[var] = value\n",
    "                if var == \"met\":\n",
    "                    value = pad_val(met.pt, -1)\n",
    "                    out[var] = value\n",
    "                if var == \"lep_isolation\":\n",
    "                    value = pad_val(lep_reliso, -1)\n",
    "                    out[var] = value\n",
    "                if var == \"lepfj_m\":\n",
    "                    value = pad_val(lep_fj_m, -1)\n",
    "                    out[var] = value\n",
    "                if var == \"candidatefj_lep_pt\":\n",
    "                    value = pad_val(candidatefj_lep.pt, -1)\n",
    "                    out[var] = value\n",
    "                if var == \"leadingfj_pt\":\n",
    "                    value = pad_val(leadingfj.pt, -1)\n",
    "                    out[var] = value\n",
    "                if var == \"leadingfj_msoftdrop\":\n",
    "                    value = pad_val(leadingfj.msoftdrop, -1)\n",
    "                    out[var] = value\n",
    "                if var == \"secondfj_pt\":\n",
    "                    value = pad_val(secondfj.pt, -1)\n",
    "                    out[var] = value\n",
    "                if var == \"secondfj_msoftdrop\":\n",
    "                    value = pad_val(secondfj.msoftdrop, -1)\n",
    "                    out[var] = value\n",
    "                if var == \"bjets_ophem_lepfj\":\n",
    "                    value = pad_val(bjets_ophem_lepfj, -1)\n",
    "                    out[var] = value\n",
    "                if var == \"bjets_ophem_leadingfj\":\n",
    "                    value = pad_val(bjets_ophem_leadingfj, -1)\n",
    "                    out[var] = value\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            # print arrays and selections to debug\n",
    "            # print(out)\n",
    "            # print(selections[ch].all(*selections[ch].names))\n",
    "\n",
    "            # apply selections\n",
    "            if np.sum(self.selections[ch].all(*self.selections[ch].names)) > 0:\n",
    "                output[ch] = {\n",
    "                    key: value[self.selections[ch].all(*self.selections[ch].names)] for (key, value) in out.items()\n",
    "                }\n",
    "            else:\n",
    "                output[ch] = {}\n",
    "\n",
    "            # convert arrays to pandas\n",
    "            if not isinstance(output[ch], pd.DataFrame):\n",
    "                output[ch] = self.ak_to_pandas(output[ch])\n",
    "\n",
    "        # now save pandas dataframes\n",
    "        fname = events.behavior[\"__events_factory__\"]._partition_key.replace(\"/\", \"_\")\n",
    "        fname = 'condor_' + fname\n",
    "        for ch in self._channels:\n",
    "            if not os.path.exists('./outfiles/' + ch):  # creating a directory for each channel\n",
    "                os.makedirs('./outfiles/' + ch)\n",
    "            if not os.path.exists('./outfiles/' + ch + self.folder_name + '/parquet'):  # creating a directory for each channel\n",
    "                os.makedirs('./outfiles/' + ch + self.folder_name + '/parquet')\n",
    "\n",
    "            self.save_dfs_parquet(fname, output[ch], ch, self.folder_name)\n",
    "\n",
    "        # return dictionary with cutflows\n",
    "        return {\n",
    "            dataset: {'mc': isMC,\n",
    "                      self._year: {'sumgenweight': sumgenweight,\n",
    "                                   'cutflows': self.cutflows}\n",
    "                      }\n",
    "        }\n",
    "\n",
    "    def postprocess(self, accumulator):\n",
    "        return accumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "078d8f8b-31a1-4780-a86d-d3bd6722617a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GluGluHToWWToLNuQQ_M125_TuneCP5_PSweight_13TeV-powheg2-jhugen727-pythia8\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "datasets = {\"GluGluHToWWToLNuQQ_M125_TuneCP5_PSweight_13TeV-powheg2-jhugen727-pythia8\": \"HWW\",\n",
    "           }\n",
    "\n",
    "# datasets = {\"QCD_Pt_1000to1400_TuneCP5_13TeV_pythia8\": \"QCD\",\n",
    "#            }\n",
    "\n",
    "fileset = {}\n",
    "for dataset_name,dataset in datasets.items():\n",
    "    print(dataset_name)\n",
    "    with open(\"../fileset/v2_2/2017.json\", 'r') as f:\n",
    "    # with open(\"../fileset_2017_UL_NANO.json\", 'r') as f:\n",
    "        files = json.load(f)[dataset][dataset_name]\n",
    "    \n",
    "    # files = [files[0], files[1]]\n",
    "    \n",
    "    # use all_files False if you want to test\n",
    "    all_files = False\n",
    "    # need to define the fileset but call them with xcache\n",
    "    if all_files:\n",
    "        fileset[dataset_name] = [\"root://xcache/\"+ f for f in files]\n",
    "    else:\n",
    "        fileset[dataset_name] = [[\"root://xcache/\"+ f for f in files][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cae6868f-e8b3-4bde-9f36-9dbace1f71dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GluGluHToWWToLNuQQ_M125_TuneCP5_PSweight_13TeV-powheg2-jhugen727-pythia8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f812327aff2479396fe33670874a0a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/10 [00:00<?, ?chunk/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/awkward/_connect/_numpy.py:207: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(\n",
      "/opt/conda/lib/python3.8/site-packages/awkward/_connect/_numpy.py:207: RuntimeWarning: invalid value encountered in sqrt\n",
      "  result = getattr(ufunc, method)(\n"
     ]
    }
   ],
   "source": [
    "import uproot\n",
    "uproot.open.defaults['xrootd_handler'] = uproot.source.xrootd.MultithreadedXRootDSource\n",
    "\n",
    "from coffea.processor import IterativeExecutor,Runner,DaskExecutor\n",
    "from coffea.nanoevents import NanoEventsFactory, NanoAODSchema\n",
    "\n",
    "dask_executor = False\n",
    "\n",
    "# remove outfiles directory cand create a new empty one\n",
    "if os.path.exists('./outfiles'):\n",
    "    shutil.rmtree('./outfiles') \n",
    "os.makedirs('./outfiles')\n",
    "\n",
    "channels = [\"ele\", \"mu\", \"had\"]\n",
    "job_name = '/' + str(0) + '-' + str(1)\n",
    "\n",
    "# define executor \n",
    "if dask_executor:\n",
    "    executor = DaskExecutor(compression=1, status=True, client=client, treereduction=2)\n",
    "else:\n",
    "    executor = IterativeExecutor(compression=1, status=True)\n",
    "\n",
    "# define the runner (Same as before)\n",
    "run = Runner(executor=executor,savemetrics=True,chunksize=10000,schema=NanoAODSchema)\n",
    "\n",
    "# run\n",
    "for dataset,dataset_files in fileset.items():\n",
    "    new_fileset = {dataset: dataset_files}\n",
    "    print(dataset)\n",
    "    hwwproc = HwwProcessor(year=\"2017\", channels=channels, output_location=\"./\", folder_name = job_name)\n",
    "    out,metrics = run(new_fileset,'Events',processor_instance=hwwproc)\n",
    "\n",
    "# save pkl file with metadata\n",
    "filehandler = open(f\"outfiles/{0}-{1}.pkl\", \"wb\")\n",
    "pkl.dump(out, filehandler)\n",
    "filehandler.close()\n",
    "    \n",
    "### merge parquet\n",
    "for ch in channels:\n",
    "    data = pd.read_parquet('./outfiles/' + ch + job_name + '/parquet')\n",
    "    data.to_parquet('./outfiles/' + job_name + '_' + ch + '.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f7beea7c-b84f-4510-9258-00be772b2442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lepton_pt</th>\n",
       "      <th>lep_isolation</th>\n",
       "      <th>met</th>\n",
       "      <th>ht</th>\n",
       "      <th>mt_lep_met</th>\n",
       "      <th>dr_jet_candlep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45.193813</td>\n",
       "      <td>0.057876</td>\n",
       "      <td>33.491756</td>\n",
       "      <td>915.062500</td>\n",
       "      <td>62.416294</td>\n",
       "      <td>0.543228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93.697174</td>\n",
       "      <td>0.006226</td>\n",
       "      <td>84.576859</td>\n",
       "      <td>533.593750</td>\n",
       "      <td>35.575668</td>\n",
       "      <td>0.264700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>135.052628</td>\n",
       "      <td>0.034041</td>\n",
       "      <td>17.041643</td>\n",
       "      <td>296.125000</td>\n",
       "      <td>28.831499</td>\n",
       "      <td>0.156955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>183.151611</td>\n",
       "      <td>1.226843</td>\n",
       "      <td>35.143532</td>\n",
       "      <td>938.500000</td>\n",
       "      <td>50.409016</td>\n",
       "      <td>0.129413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91.765190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.237423</td>\n",
       "      <td>491.265625</td>\n",
       "      <td>42.532780</td>\n",
       "      <td>0.274371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>203.937988</td>\n",
       "      <td>0.497827</td>\n",
       "      <td>22.961908</td>\n",
       "      <td>729.687500</td>\n",
       "      <td>43.725430</td>\n",
       "      <td>0.095726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>66.315811</td>\n",
       "      <td>0.411241</td>\n",
       "      <td>207.669296</td>\n",
       "      <td>685.000000</td>\n",
       "      <td>34.255898</td>\n",
       "      <td>0.255994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>53.196495</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65.714912</td>\n",
       "      <td>859.687500</td>\n",
       "      <td>97.761101</td>\n",
       "      <td>0.381320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>64.263313</td>\n",
       "      <td>0.120652</td>\n",
       "      <td>19.147688</td>\n",
       "      <td>441.875000</td>\n",
       "      <td>61.800560</td>\n",
       "      <td>0.308392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>281.739380</td>\n",
       "      <td>0.338356</td>\n",
       "      <td>98.942612</td>\n",
       "      <td>1388.187500</td>\n",
       "      <td>10.270407</td>\n",
       "      <td>0.058335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lepton_pt  lep_isolation         met           ht  mt_lep_met  \\\n",
       "0     45.193813       0.057876   33.491756   915.062500   62.416294   \n",
       "1     93.697174       0.006226   84.576859   533.593750   35.575668   \n",
       "2    135.052628       0.034041   17.041643   296.125000   28.831499   \n",
       "3    183.151611       1.226843   35.143532   938.500000   50.409016   \n",
       "4     91.765190       0.000000   35.237423   491.265625   42.532780   \n",
       "..          ...            ...         ...          ...         ...   \n",
       "109  203.937988       0.497827   22.961908   729.687500   43.725430   \n",
       "110   66.315811       0.411241  207.669296   685.000000   34.255898   \n",
       "111   53.196495       0.000000   65.714912   859.687500   97.761101   \n",
       "112   64.263313       0.120652   19.147688   441.875000   61.800560   \n",
       "113  281.739380       0.338356   98.942612  1388.187500   10.270407   \n",
       "\n",
       "     dr_jet_candlep  \n",
       "0          0.543228  \n",
       "1          0.264700  \n",
       "2          0.156955  \n",
       "3          0.129413  \n",
       "4          0.274371  \n",
       "..              ...  \n",
       "109        0.095726  \n",
       "110        0.255994  \n",
       "111        0.381320  \n",
       "112        0.308392  \n",
       "113        0.058335  \n",
       "\n",
       "[114 rows x 6 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load parquet data\n",
    "import pandas as pd\n",
    "data = pq.read_table('./outfiles/0-1_mu.parquet')\n",
    "data = data.to_pandas()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "99c07fba-0f46-4ad8-b6bc-a167d19a2704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GluGluHToWWToLNuQQ_M125_TuneCP5_PSweight_13TeV-powheg2-jhugen727-pythia8': {'mc': 10,\n",
       "  '2017': {'cutflows': {'ele': {'mt': 91,\n",
       "     'leptonInJet': 139,\n",
       "     'trigger': 5680,\n",
       "     'metfilters': 5679,\n",
       "     'oneLepton': 89,\n",
       "     'ht': 137,\n",
       "     'leptonKin': 90,\n",
       "     'leptonIsolation': 87,\n",
       "     'all': 98400},\n",
       "    'had': {'softdrop': 18,\n",
       "     'trigger': 98400,\n",
       "     'metfilters': 98361,\n",
       "     'oneFatjet': 844,\n",
       "     'qcdrho': 17,\n",
       "     'leadingJet': 39,\n",
       "     'all': 98400},\n",
       "    'mu': {'mt': 114,\n",
       "     'leptonInJet': 164,\n",
       "     'trigger': 10877,\n",
       "     'metfilters': 10872,\n",
       "     'oneLepton': 8977,\n",
       "     'ht': 161,\n",
       "     'leptonKin': 8981,\n",
       "     'leptonIsolation': 8907,\n",
       "     'all': 98400}},\n",
       "   'sumgenweight': 2842898.2}}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load pickle metadata\n",
    "with open('./outfiles/0-1.pkl', 'rb') as f:\n",
    "    metadata = pkl.load(f)\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1e4a22-4544-45db-bf5c-be2f0b13f60c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
